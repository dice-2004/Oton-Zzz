#!/usr/bin/env python3
"""
Oton-Zzz ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ« (ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å¯¾å¿œ)
ç¡çœ æ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¯¾è©±çš„ã«èª¿æ•´
ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ãªã—ã§ã‚‚ä½¿ç”¨å¯èƒ½
"""

import cv2
import time
import mediapipe as mp
import argparse
import json
from config_manager import ConfigManager
from ir_sleep_detector import SleepDetector
from voice_controller import VoiceController


def run_test_detection_headless(detector, voice, duration_seconds=30):
    """
    ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆæ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆç”»é¢å‡ºåŠ›ãªã—ï¼‰

    Args:
        detector: SleepDetectorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        voice: VoiceControllerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        duration_seconds: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
    """
    BaseOptions = mp.tasks.BaseOptions
    FaceLandmarker = mp.tasks.vision.FaceLandmarker
    FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
    VisionRunningMode = mp.tasks.vision.RunningMode

    options = FaceLandmarkerOptions(
        base_options=BaseOptions(model_asset_path=detector.model_path),
        running_mode=VisionRunningMode.LIVE_STREAM,
        num_faces=1,
        output_face_blendshapes=True,
        result_callback=detector.result_callback
    )

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âœ— ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        voice.speak("ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        return

    print(f"\nğŸ“¹ {duration_seconds}ç§’é–“ãƒ†ã‚¹ãƒˆæ¤œå‡ºã‚’å®Ÿè¡Œã—ã¾ã™...")
    voice.speak(f"{duration_seconds}ç§’é–“ã€ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™ã€‚ã‚«ãƒ¡ãƒ©ã‚’è¦‹ã¦ãã ã•ã„ã€‚")
    print("=" * 60)

    # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
    blink_scores = []
    gauge_values = []
    stage1_count = 0
    stage2_count = 0

    try:
        with FaceLandmarker.create_from_options(options) as landmarker:
            start_time = time.time()
            test_start = time.time()
            last_voice_time = 0

            while True:
                elapsed = time.time() - test_start
                if elapsed >= duration_seconds:
                    break

                ret, frame = cap.read()
                if not ret:
                    break

                frame = cv2.flip(frame, 1)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                timestamp_ms = int((time.time() - start_time) * 1000)
                landmarker.detect_async(mp_image, timestamp_ms)

                gauge_value, is_stage1, is_stage2, status = detector.process_result()

                # ã¾ã°ãŸãã‚¹ã‚³ã‚¢ã‚’å–å¾—
                left, right, avg = detector.get_eye_blink_values()

                # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿åé›†
                if avg > 0:
                    blink_scores.append(avg)
                gauge_values.append(gauge_value)

                if is_stage1:
                    stage1_count += 1
                if is_stage2:
                    stage2_count += 1

                # 5ç§’ã”ã¨ã«é€²æ—ã‚’éŸ³å£°é€šçŸ¥
                if elapsed - last_voice_time >= 5.0:
                    voice.speak(f"çµŒé{int(elapsed)}ç§’ã€‚ã¾ã°ãŸãã‚¹ã‚³ã‚¢å¹³å‡{avg:.2f}")
                    last_voice_time = elapsed

                # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è©³ç´°æƒ…å ±ã‚’å‡ºåŠ›
                print(f"\rçµŒé: {elapsed:.1f}s | Blink: {avg:.2f} | Gauge: {gauge_value:.1f}/{detector.GAUGE_MAX:.1f} | {status}", end='')

                time.sleep(0.05)  # CPUè² è·è»½æ¸›

    except KeyboardInterrupt:
        print("\nâš ï¸  ãƒ†ã‚¹ãƒˆã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
        voice.speak("ãƒ†ã‚¹ãƒˆã‚’ä¸­æ–­ã—ã¾ã—ãŸ")

    finally:
        cap.release()
        print("\n" + "=" * 60)
        print("âœ“ ãƒ†ã‚¹ãƒˆå®Œäº†\n")

        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        if blink_scores:
            print("ã€çµ±è¨ˆæƒ…å ±ã€‘")
            print(f"  ã¾ã°ãŸãã‚¹ã‚³ã‚¢:")
            print(f"    - å¹³å‡: {sum(blink_scores)/len(blink_scores):.3f}")
            print(f"    - æœ€å¤§: {max(blink_scores):.3f}")
            print(f"    - æœ€å°: {min(blink_scores):.3f}")
            print(f"  ç¡çœ ã‚²ãƒ¼ã‚¸:")
            print(f"    - å¹³å‡: {sum(gauge_values)/len(gauge_values):.2f}")
            print(f"    - æœ€å¤§: {max(gauge_values):.2f}")
            print(f"  Stage1æ¤œçŸ¥å›æ•°: {stage1_count}")
            print(f"  Stage2æ¤œçŸ¥å›æ•°: {stage2_count}")
            print("=" * 60)

            voice.speak(f"ãƒ†ã‚¹ãƒˆå®Œäº†ã€‚ã¾ã°ãŸãã‚¹ã‚³ã‚¢å¹³å‡ã¯{sum(blink_scores)/len(blink_scores):.2f}ã§ã—ãŸã€‚")


def run_test_detection_with_display(detector, duration_seconds=30):
    """
    ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚ã‚Šã§ãƒ†ã‚¹ãƒˆæ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆå¾“æ¥ã®æ–¹æ³•ï¼‰

    Args:
        detector: SleepDetectorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        duration_seconds: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
    """
    BaseOptions = mp.tasks.BaseOptions
    FaceLandmarker = mp.tasks.vision.FaceLandmarker
    FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
    VisionRunningMode = mp.tasks.vision.RunningMode

    options = FaceLandmarkerOptions(
        base_options=BaseOptions(model_asset_path=detector.model_path),
        running_mode=VisionRunningMode.LIVE_STREAM,
        num_faces=1,
        output_face_blendshapes=True,
        result_callback=detector.result_callback
    )

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âœ— ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        return

    print(f"\nğŸ“¹ {duration_seconds}ç§’é–“ãƒ†ã‚¹ãƒˆæ¤œå‡ºã‚’å®Ÿè¡Œã—ã¾ã™...")
    print("=" * 60)

    try:
        with FaceLandmarker.create_from_options(options) as landmarker:
            start_time = time.time()
            test_start = time.time()

            while True:
                elapsed = time.time() - test_start
                if elapsed >= duration_seconds:
                    break

                ret, frame = cap.read()
                if not ret:
                    break

                frame = cv2.flip(frame, 1)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                timestamp_ms = int((time.time() - start_time) * 1000)
                landmarker.detect_async(mp_image, timestamp_ms)

                gauge_value, is_stage1, is_stage2, status = detector.process_result()

                # ã¾ã°ãŸãã‚¹ã‚³ã‚¢ã‚’å–å¾—
                left, right, avg = detector.get_eye_blink_values()

                # ç”»é¢è¡¨ç¤º
                color = (0, 255, 0)
                if "Confirmed" in status:
                    color = (0, 0, 255)
                elif "Confirmation" in status:
                    color = (0, 165, 255)
                elif "Closed" in status:
                    color = (0, 255, 255)

                cv2.putText(frame, f"Status: {status}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
                cv2.putText(frame, f"Blink Score: L={left:.2f} R={right:.2f} Avg={avg:.2f}", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(frame, f"Threshold: {detector.BLINK_THRESHOLD:.2f}", (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
                cv2.putText(frame, f"Gauge: {gauge_value:.1f} / {detector.GAUGE_MAX:.1f}", (10, 170), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
                cv2.putText(frame, f"Time: {elapsed:.1f}s / {duration_seconds}s", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)

                # ã‚²ãƒ¼ã‚¸ãƒãƒ¼
                gauge_percentage = gauge_value / detector.GAUGE_MAX if detector.GAUGE_MAX > 0 else 0
                bar_width = int(gauge_percentage * (frame.shape[1] - 20))
                cv2.rectangle(frame, (10, 230), (frame.shape[1] - 10, 260), (255, 255, 255), 2)
                cv2.rectangle(frame, (10, 230), (10 + bar_width, 260), color, -1)

                cv2.imshow("Calibration Test", frame)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

    except KeyboardInterrupt:
        print("\nâš ï¸  ãƒ†ã‚¹ãƒˆã‚’ä¸­æ–­ã—ã¾ã—ãŸ")

    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("=" * 60)
        print("âœ“ ãƒ†ã‚¹ãƒˆå®Œäº†")


def main():
    """ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='Oton-Zzz ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--headless', action='store_true', help='ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ãªã—ï¼‰')
    args = parser.parse_args()

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      Oton-Zzz ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ« v2.0              â•‘
â•‘      ç¡çœ æ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    if args.headless:
        print("ğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™")
        # éŸ³å£°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–
        try:
            voice = VoiceController()
            voice.speak("ãŠã¨ã‚“ZZZã€ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã‚’èµ·å‹•ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âš ï¸  éŸ³å£°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
            voice = None
    else:
        print("ğŸ–¥ï¸  é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚ã‚Šï¼‰ã§èµ·å‹•ã—ã¾ã™")
        voice = None

    # è¨­å®šãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–
    config_mgr = ConfigManager()
    config_mgr.print_params()

    while True:
        print("\nã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã€‘")
        print("1. ç¾åœ¨ã®è¨­å®šã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ (30ç§’)")
        print("2. ã¾ã°ãŸãé–¾å€¤ (BLINK_THRESHOLD) ã‚’å¤‰æ›´")
        print("3. ç¡çœ ã‚²ãƒ¼ã‚¸æœ€å¤§å€¤ (GAUGE_MAX) ã‚’å¤‰æ›´")
        print("4. ã‚²ãƒ¼ã‚¸å¢—åŠ é€Ÿåº¦ (GAUGE_INCREASE_RATE) ã‚’å¤‰æ›´")
        print("5. ã‚²ãƒ¼ã‚¸æ¸›å°‘é€Ÿåº¦ (GAUGE_DECREASE_RATE) ã‚’å¤‰æ›´")
        print("6. æœ€çµ‚ç¢ºèªæ™‚é–“ (FINAL_CONFIRMATION_TIME) ã‚’å¤‰æ›´")
        print("7. è¨­å®šã‚’è¡¨ç¤º")
        print("8. è¨­å®šã‚’ä¿å­˜ã—ã¦çµ‚äº†")
        print("9. ä¿å­˜ã›ãšã«çµ‚äº†")

        choice = input("\né¸æŠã—ã¦ãã ã•ã„ (1-9): ").strip()

        if choice == '1':
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            params = config_mgr.get_sleep_detection_params()
            detector = SleepDetector(
                blink_threshold=params.get('blink_threshold', 0.5),
                gauge_max=params.get('gauge_max', 5.0),
                gauge_increase_rate=params.get('gauge_increase_rate', 1.0),
                gauge_decrease_rate=params.get('gauge_decrease_rate', 1.5),
                final_confirmation_time=params.get('final_confirmation_time', 5.0)
            )

            if args.headless:
                run_test_detection_headless(detector, voice, duration_seconds=30)
            else:
                run_test_detection_with_display(detector, duration_seconds=30)

        elif choice == '2':
            print("\nã€ã¾ã°ãŸãé–¾å€¤ã®èª¿æ•´ã€‘")
            print("ç›®ã‚’é–‰ã˜ãŸã¨åˆ¤å®šã™ã‚‹é–¾å€¤ã§ã™ã€‚")
            print("å€¤ãŒå°ã•ã„ã»ã©ã€Œé–‰ã˜ãŸã€ã¨åˆ¤å®šã•ã‚Œã‚„ã™ããªã‚Šã¾ã™ã€‚")
            print("æ¨å¥¨ç¯„å›²: 0.4 ã€œ 0.6")
            try:
                value = float(input("æ–°ã—ã„å€¤ã‚’å…¥åŠ› (ç¾åœ¨: {}): ".format(config_mgr.get_sleep_detection_params().get('blink_threshold', 0.5))))
                config_mgr.update_sleep_detection_params(blink_threshold=value)
                if voice:
                    voice.speak(f"ã¾ã°ãŸãé–¾å€¤ã‚’{value}ã«å¤‰æ›´ã—ã¾ã—ãŸ")
            except ValueError:
                print("âœ— ç„¡åŠ¹ãªå€¤ã§ã™")

        elif choice == '3':
            print("\nã€ç¡çœ ã‚²ãƒ¼ã‚¸æœ€å¤§å€¤ã®èª¿æ•´ã€‘")
            print("ç›®ã‚’é–‰ã˜ç¶šã‘ã¦ã“ã®å€¤ã«é”ã™ã‚‹ã¨ç¡çœ Stage1ã¨åˆ¤å®šã•ã‚Œã¾ã™ã€‚")
            print("æ¨å¥¨ç¯„å›²: 3.0 ã€œ 7.0 (ç§’æ•°ç›¸å½“)")
            try:
                value = float(input("æ–°ã—ã„å€¤ã‚’å…¥åŠ› (ç¾åœ¨: {}): ".format(config_mgr.get_sleep_detection_params().get('gauge_max', 5.0))))
                config_mgr.update_sleep_detection_params(gauge_max=value)
                if voice:
                    voice.speak(f"ã‚²ãƒ¼ã‚¸æœ€å¤§å€¤ã‚’{value}ã«å¤‰æ›´ã—ã¾ã—ãŸ")
            except ValueError:
                print("âœ— ç„¡åŠ¹ãªå€¤ã§ã™")

        elif choice == '4':
            print("\nã€ã‚²ãƒ¼ã‚¸å¢—åŠ é€Ÿåº¦ã®èª¿æ•´ã€‘")
            print("ç›®ã‚’é–‰ã˜ã¦ã„ã‚‹ã¨ãã®ã‚²ãƒ¼ã‚¸å¢—åŠ é€Ÿåº¦ã§ã™ã€‚")
            print("æ¨å¥¨ç¯„å›²: 0.8 ã€œ 1.5 (ãƒã‚¤ãƒ³ãƒˆ/ç§’)")
            try:
                value = float(input("æ–°ã—ã„å€¤ã‚’å…¥åŠ› (ç¾åœ¨: {}): ".format(config_mgr.get_sleep_detection_params().get('gauge_increase_rate', 1.0))))
                config_mgr.update_sleep_detection_params(gauge_increase_rate=value)
                if voice:
                    voice.speak(f"ã‚²ãƒ¼ã‚¸å¢—åŠ é€Ÿåº¦ã‚’{value}ã«å¤‰æ›´ã—ã¾ã—ãŸ")
            except ValueError:
                print("âœ— ç„¡åŠ¹ãªå€¤ã§ã™")

        elif choice == '5':
            print("\nã€ã‚²ãƒ¼ã‚¸æ¸›å°‘é€Ÿåº¦ã®èª¿æ•´ã€‘")
            print("ç›®ã‚’é–‹ã„ã¦ã„ã‚‹ã¨ãã®ã‚²ãƒ¼ã‚¸æ¸›å°‘é€Ÿåº¦ã§ã™ã€‚")
            print("æ¨å¥¨ç¯„å›²: 1.0 ã€œ 2.0 (ãƒã‚¤ãƒ³ãƒˆ/ç§’)")
            try:
                value = float(input("æ–°ã—ã„å€¤ã‚’å…¥åŠ› (ç¾åœ¨: {}): ".format(config_mgr.get_sleep_detection_params().get('gauge_decrease_rate', 1.5))))
                config_mgr.update_sleep_detection_params(gauge_decrease_rate=value)
                if voice:
                    voice.speak(f"ã‚²ãƒ¼ã‚¸æ¸›å°‘é€Ÿåº¦ã‚’{value}ã«å¤‰æ›´ã—ã¾ã—ãŸ")
            except ValueError:
                print("âœ— ç„¡åŠ¹ãªå€¤ã§ã™")

        elif choice == '6':
            print("\nã€æœ€çµ‚ç¢ºèªæ™‚é–“ã®èª¿æ•´ã€‘")
            print("Stage1æ¤œçŸ¥å¾Œã€Stage2ï¼ˆå®Ÿéš›ã«ãƒ†ãƒ¬ãƒ“ã‚’æ¶ˆã™ï¼‰ã¾ã§ã®å¾…æ©Ÿæ™‚é–“ã§ã™ã€‚")
            print("æ¨å¥¨ç¯„å›²: 3.0 ã€œ 10.0 (ç§’)")
            try:
                value = float(input("æ–°ã—ã„å€¤ã‚’å…¥åŠ› (ç¾åœ¨: {}): ".format(config_mgr.get_sleep_detection_params().get('final_confirmation_time', 5.0))))
                config_mgr.update_sleep_detection_params(final_confirmation_time=value)
                if voice:
                    voice.speak(f"æœ€çµ‚ç¢ºèªæ™‚é–“ã‚’{value}ç§’ã«å¤‰æ›´ã—ã¾ã—ãŸ")
            except ValueError:
                print("âœ— ç„¡åŠ¹ãªå€¤ã§ã™")

        elif choice == '7':
            config_mgr.print_params()

        elif choice == '8':
            print("\nè¨­å®šã‚’ä¿å­˜ã—ã¦ã„ã¾ã™...")
            if config_mgr.save():
                print("âœ“ è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚çµ‚äº†ã—ã¾ã™ã€‚")
                if voice:
                    voice.speak("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚çµ‚äº†ã—ã¾ã™")
                break
            else:
                print("âœ— ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")

        elif choice == '9':
            print("\nä¿å­˜ã›ãšã«çµ‚äº†ã—ã¾ã™ã€‚")
            if voice:
                voice.speak("ä¿å­˜ã›ãšã«çµ‚äº†ã—ã¾ã™")
            break

        else:
            print("âœ— ç„¡åŠ¹ãªé¸æŠã§ã™")


if __name__ == '__main__':
    main()
